---
title: "Defining Anchors with S7 classes"
---


```{r}
library(S7)

predicate <- new_class("predicate", 
  properties = list(
    feature = class_character,
    operator = class_function,
    constant = new_union(
      class_integer, class_double, class_character
    )
  ),
  validator = function(self) {
  }
)

anchors <- new_class("anchors",
  properties = list(
    predicates = class_vector # a vector of predicate class
  ),
  validator = function(self) {
    if(!all(sapply(self@predicates, \(x) S7_inherits(x, predicate)))) {
      return("The list of predicates should all inherit from the predicate class ")
    }
  }
)
```


```{r}
a1 <- predicate("x1", `>=`, 10)
a2 <- predicate("x2", `<`, 20)
A <- anchors(c(a1, a2))
A <- anchors()
```

```{r}
extend <- new_generic("extend", "x")
#' @param pred The predicate to extend x with
#' @return Extended anchor
method(extend, anchors) <- function(x, pred) {
  x@predicates <- c(x@predicates, pred)
  return(x)
}
```


```{r}
satisfies <- new_generic("satisfies", "x")
#' @param data The dataframe to apply anchors on. Can be one instance or an entire dataset. 
#' @return A logical vector indicating whether the anchors satisfies `data`
method(satisfies, anchors) <- function(x, data) {
  predicate_cols <- sapply(x@predicates, \(x) x@feature)
  if(!all(predicate_cols %in% colnames(data))) {
    stop(glue::glue(
      "Predicates contain the following columns \n {predicate_cols}\n",
      "that might not be in the dataset with the following columns \n {colnames(data)}"))
  }
  satis_list <- rep(TRUE, nrow(data))
  for(predicate in x@predicates) {
    result_list <- predicate@operator(data[[predicate@feature]], predicate@constant)
    satis_list <- satis_list & result_list
  }
  return(satis_list)
}
```

```{r}
precision <- new_generic("precision", "x")
#' @param model a predict function that will provide the predicted labels given a dataset
#' @param dist the function that can be used to generate samples by providing an argument n. Should return a dataframe with proper column names.
#' @param n_samples the number of samples to generate from `dist` (the perturbation distribution)
#' @return named vector of proportions
method(precision, anchors) <- function(x, model, dist, n_samples = 100) {
  samples <- dist(n = n_samples)
  samples <- samples[satisfies(x, samples), ]
  preds <- model(samples)
  return(prop = as.vector(table(preds) / sum(table(preds))))
}
```

```{r}
coverage <- new_generic("coverage", "x")
#' @param dist the function that can be used to generate samples by providing an argument n. Should return a dataframe with proper column names.
#' @param n_samples the number of samples to generate from `dist` (the perturbation distribution)
method(coverage, anchors) <- function(x, dist, n_samples = 100) {
  samples <- dist(n = n_samples)
  return(mean(satisfies(x, samples)))
}
```


```{r}
library(testthat)
describe("anchors", {
  it("should satisfy all data points in a dataset if no predicates is present", {
    # Arrange
    A <- anchors()
    data <- data.frame(x1 = rnorm(10), x2 = rnorm(10))
    # Act 
    result <- satisfies(A, data)
    # Assert
    expect_true(all(result))
  })
  it("should be extendable", {
    # Arrange
    A <- anchors()
    B <- anchors(c(predicate("B", `<=`, 8)))
    # Act
    extend_pred <- predicate("A", `>=`, 4)
    A_ex <- extend(A, extend_pred)
    B_ex <- extend(B, extend_pred)
    # Assert
    expect_true(S7_inherits(A_ex, anchors))
    expect_true(S7_inherits(B_ex, anchors))
    expect_true(length(A_ex@predicates) == 1)
    expect_true(length(B_ex@predicates) == 2)
  })
  it("should satisfy the correct data points that are specific to predicates", {
    # Arrange
    A <- anchors(c(predicate("B", `<=`, 8), predicate("A", `>=`, 3)))
    data <- data.frame(A = seq(1,10), B = seq(1,10) * 2)
    # Act
    result <- satisfies(A, data)
    # Assert
    expect_equal(result, c(F,F,T,T,F,F,F,F,F,F))
  })
  it("should calculate some precision for some anchor", {
    # Arrange
    A <- anchors(c(predicate("B", `<=`, 8), predicate("A", `>=`, 3)))
    model_func <- function(data) {
      sample(c("Y", "N"), nrow(data), replace = TRUE)
    }
    dist_func <- function(n) {
      return(
        data.frame(
          A = runif(n, min = 4.5, max = 5.5),
          B = runif(n, min = 4.5, max = 5.5))
      )
    }
    # Act
    prec <- precision(A, model_func, dist_func)
    # Assert
    expect_vector(prec, ptype = double())
  })
  it("should calculate the coverage for a given anchor", {
    # Arrange
    A <- anchors(c(predicate("B", `<=`, 8), predicate("A", `>=`, 3)))
    dist_func <- function(n) {
      return(
        data.frame(
          A = c(4,6,7,8,0,2,1,2,2),
          B = c(2,3,4,5,1,9,9,9,8)
        )
      )
    }
    # Act
    covr <- coverage(A, dist_func)
    # Assert
    expect_vector(covr, ptype = double())
  })
})
```

```{r}
# load wiggly dataset
library(tidyverse)
theme_set(theme_minimal())
w <- read_csv("wiggly.csv") |> mutate(class = factor(ifelse(class == 3, "Positive", "Negative"))) |> select(-`...1`)
w |> ggplot(aes(x = x,y = y,color = class)) + geom_point()
```

```{r}
# sample train data
set.seed(69420)
train_indices <- sample(nrow(w), round(nrow(w) * 0.8))
w[train_indices, ] |> ggplot(aes(x = x,y = y,color = class)) + geom_point()
```

```{r}
train_df <- w[train_indices, ] |> mutate(id = row_number())
library(randomForest)
rfmodel <- randomForest(class ~ x + y, data = train_df, ntree = 5)
rfmodel
```


```{r}
# select instance
prob_matrix <- predict(rfmodel, newdata = train_df, type = "prob") |> 
  as.data.frame() |>
  mutate(id = row_number())
local_instance <- prob_matrix[prob_matrix$Negative == 0.4, "id"]
print(local_instance)
local_instance <- local_instance[1]
```


```{r}
train_df[-local_instance, ] |>
  ggplot(aes(x = x,y = y,color = class)) +
  geom_point() +
  geom_point(data = train_df[local_instance, ], size = 5, color = "black")
```

```{r}
# generate cutpoints
x_vals <- train_df[-local_instance,][["x"]] |> sort()
x_cutpoints <- purrr::map2_dbl(x_vals[-length(x_vals)], x_vals[-1], function(x, x_1) {
  return(mean(c(x, x_1)))
})
x_grid <- expand.grid(
  x_cutpoints[x_cutpoints < train_df[local_instance,]$x],
  x_cutpoints[x_cutpoints > train_df[local_instance,]$x]
) |> rename(a = Var1, b = Var2)

y_vals <- train_df[-local_instance,][["y"]] |> sort()
y_cutpoints <- purrr::map2_dbl(y_vals[-length(y_vals)], y_vals[-1], function(x, x_1) {
  return(mean(c(x, x_1)))
})
y_grid <- expand.grid(
  y_cutpoints[y_cutpoints < train_df[local_instance,]$y],
  y_cutpoints[y_cutpoints > train_df[local_instance,]$y]
) |> rename(c = Var1, d = Var2)

grid <- expand_grid(x_grid, y_grid)
```

```{r}
pertub_func <- function(n) {
  mulgar::rmvn(n = n, 
               p = 2,
               mn = train_df[local_instance, c("x", "y")] |> 
                 unlist(),
               vc = cov(train_df[,c("x", "y")])
  ) |>
    as.data.frame() |>
    rename(x = x1, y = x2)
}

model_func <- function(data_samples) {
  return(predict(rfmodel, data_samples))
}

set.seed(123)
samples <- pertub_func(n = 1000)
dist_func <- function(n) samples[1:n, ]
```


```{r}
library(future.apply)
plan(multisession)

res <- grid |> head(10000) |> apply(1, function(row) {
  bound <- anchors(c(
    predicate(feature = "x",operator = `>`,constant = row["a"]),
    predicate(feature = "x",operator = `<`,constant = row["b"]),
    predicate(feature = "y",operator = `>`,constant = row["c"]),
    predicate(feature = "y",operator = `<`,constant = row["d"])
  ))
  cover <- coverage(bound, dist_func, n_samples = 500)
  prec <- precision(bound, model_func, dist_func, n_samples = 500)
  return(list(cover = cover, prec = prec))
})
```

```{r}
res_df <- res |> map_dfr(~ tibble(cover = .x$cover, prec_1 = .x$prec[1], prec_2 = .x$prec[2]))
```

```{r}
res_df |> ggplot(aes(x = prec_1, y = cover))+geom_point() + geom_vline(xintercept = 0.8)
```

```{r}
set.seed(452)
# test_bounds <- res_df |> mutate(id = row_number()) |> filter(prec_1 == 1) |> select(id) |> unlist()
test_bounds <- res_df |> mutate(id = row_number()) |> filter(prec_1 >= 0.9) |> select(id) |> unlist()

grid |>
  mutate(id = row_number()) |>
  filter(id %in% test_bounds) |>
  sample_n(size = 11) |>
  ggplot() +
  geom_point(data = samples[1:500, ] |> mutate(cls = predict(rfmodel, samples[1:500,])),
             aes(x = x,y = y, color = cls), size = 0.5, show.legend = F) +
  geom_point(data = train_df[local_instance, ], aes(x = x,y = y),color = "purple") +
  geom_rect(aes(xmin = a, xmax = b, ymin = c, ymax = d),color = "black", fill="transparent") +
  facet_wrap(~id,scales = "free", nrow = 3)
```

```{r}
# test_bound_row_ <- grid |> slice(271)
# test_bound_ <- anchors(c(
#     predicate(feature = "x",operator = `>`,constant = test_bound_row_[["a"]]),
#     predicate(feature = "x",operator = `<`,constant = test_bound_row_[["b"]]),
#     predicate(feature = "y",operator = `>`,constant = test_bound_row_[["c"]]),
#     predicate(feature = "y",operator = `<`,constant = test_bound_row_[["d"]])
#   ))
# samples_ <- dist_func(n = 100)
# samples_ <- samples_[satisfies(test_bound_, samples_), ]
# preds <- predict(rfmodel, samples_)
# as.vector(table(preds) / sum(table(preds)))
```


```{r}
tau <- 0.7
best_anchor <- anchors()
generate_candidates <- function(best_anchor, data) {
  
}
while(TRUE) {
  # generate candidates
  anchor_candidates <- generate_candidates(best_anchor, data)
  # select best candidate
  best_anchor <- get_best_anchor()
  # stopping criteria
  if(precision(best_anchor) >= tau) {
    break
  }
}
```

```{r}
describe("generate_candidates", {
  it("should return a list of predicates", {
    # Arrange
    first_anchor <- anchors()
    data <- data.frame(
      A = rnorm(10),
      B = rnorm(10)
    )
    # Act
    generate_candidates()
    # Assert
  })
})
```

